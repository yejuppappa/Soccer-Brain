"""
Soccer-Brain XGBoost V8 ëª¨ë¸ - ìë™ ê°€ì¤‘ì¹˜ í•™ìŠµ
==============================================
í•µì‹¬ ì›ì¹™:
  - í”¼ì²˜ëŠ” ê°€ê³µí•˜ë˜, ìµœì¢… ê°€ì¤‘ì¹˜ëŠ” XGBoostê°€ í•™ìŠµ!
  - ìˆ˜ë™ ê°€ì¤‘ì¹˜ ì„¤ì • ì—†ìŒ
  - Walk-Forward ê²€ì¦: 2021-2024 í•™ìŠµ â†’ 2025 í…ŒìŠ¤íŠ¸

ì‚¬ìš©ë²•:
  python scripts/train_xgboost_v8.py
"""

import os
import sys
import json
from datetime import datetime

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
import xgboost as xgb

import psycopg2
from dotenv import load_dotenv

load_dotenv()

DATABASE_URL = os.getenv("DATABASE_URL")


def get_features_from_db():
    """DBì—ì„œ Feature ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì‹œì¦Œ ì •ë³´ í¬í•¨)"""
    print("ğŸ“Š DBì—ì„œ Feature ë°ì´í„° ë¡œë”© ì¤‘...")
    
    conn = psycopg2.connect(DATABASE_URL)
    
    query = """
    SELECT 
        f.id,
        f."fixtureId",
        f."kickoffAt",
        f.season,
        f."leagueId",
        f."homeGoals",
        f."awayGoals",
        
        -- ë¶€ìƒ
        f."homeInjuryCount",
        f."awayInjuryCount",
        
        -- í™ˆíŒ€ ìµœê·¼ í‰ê· 
        f."home_shotsTotal_avg",
        f."home_shotsOnTarget_avg",
        f."home_possessionPct_avg",
        f."home_passAccuracyPct_avg",
        f."home_corners_avg",
        f."home_xg_avg",
        f."home_goalsFor_avg",
        f."home_goalsAgainst_avg",
        
        -- ì–´ì›¨ì´íŒ€ ìµœê·¼ í‰ê· 
        f."away_shotsTotal_avg",
        f."away_shotsOnTarget_avg",
        f."away_possessionPct_avg",
        f."away_passAccuracyPct_avg",
        f."away_corners_avg",
        f."away_xg_avg",
        f."away_goalsFor_avg",
        f."away_goalsAgainst_avg",
        
        -- í™ˆ/ì›ì • ë¶„ë¦¬
        f."home_goalsFor_atHome_avg",
        f."home_goalsAgainst_atHome_avg",
        f."home_xg_atHome_avg",
        f."home_wins_atHome_pct",
        f."away_goalsFor_atAway_avg",
        f."away_goalsAgainst_atAway_avg",
        f."away_xg_atAway_avg",
        f."away_wins_atAway_pct",
        
        -- í¼
        f."home_form_last3",
        f."home_form_last5",
        f."away_form_last3",
        f."away_form_last5",
        
        -- í”¼ë¡œë„
        f."home_days_rest",
        f."away_days_rest",
        f."rest_diff",
        f."home_matches_14d",
        f."away_matches_14d",
        
        -- H2H
        f."h2h_total_matches",
        f."h2h_home_wins",
        f."h2h_away_wins",
        f."h2h_draws",
        f."h2h_home_win_pct"
        
    FROM "FixtureFeatureSnapshot" f
    WHERE f."homeGoals" IS NOT NULL 
      AND f."awayGoals" IS NOT NULL
      AND f."featureVersion" = 5
    ORDER BY f."kickoffAt"
    """
    
    df = pd.read_sql(query, conn)
    conn.close()
    
    # ì—°ë„ ì¶”ì¶œ
    df['year'] = pd.to_datetime(df['kickoffAt']).dt.year
    
    print(f"âœ… {len(df)} ê²½ê¸° ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"   ì—°ë„ ë¶„í¬: {df['year'].value_counts().sort_index().to_dict()}")
    
    return df


def create_features(df):
    """
    í”¼ì²˜ ê°€ê³µ - ë‹¨, ìµœì¢… ê°€ì¤‘ì¹˜ëŠ” XGBoostê°€ í•™ìŠµ!
    ìˆ˜ë™ ê°€ì¤‘ì¹˜ ì¡°í•©(v8_score ê°™ì€ ê²ƒ) ì—†ìŒ
    """
    print("\nğŸ”§ í”¼ì²˜ ê°€ê³µ ì‹œì‘ (ê°€ì¤‘ì¹˜ëŠ” XGBoostê°€ í•™ìŠµ)")
    
    # ==========================================
    # 1. í¼ ê´€ë ¨ íŒŒìƒ í”¼ì²˜
    # ==========================================
    # í¼ ì°¨ì´
    df['form_diff_last3'] = df['home_form_last3'].fillna(1) - df['away_form_last3'].fillna(1)
    df['form_diff_last5'] = df['home_form_last5'].fillna(1) - df['away_form_last5'].fillna(1)
    
    # í¼ ë³€í™” (3ê²½ê¸° vs 5ê²½ê¸°)
    df['home_form_trend'] = df['home_form_last3'].fillna(1) - df['home_form_last5'].fillna(1)
    df['away_form_trend'] = df['away_form_last3'].fillna(1) - df['away_form_last5'].fillna(1)
    
    # ==========================================
    # 2. xG ê´€ë ¨ íŒŒìƒ í”¼ì²˜
    # ==========================================
    df['xg_diff'] = df['home_xg_avg'].fillna(1.2) - df['away_xg_avg'].fillna(1.0)
    df['xg_home_diff'] = df['home_xg_atHome_avg'].fillna(1.3) - df['away_xg_atAway_avg'].fillna(0.9)
    
    # xG ëŒ€ë¹„ ì‹¤ì œ ë“ì  (ì˜¤ë²„í¼í¼/ì–¸ë”í¼í¼)
    df['home_xg_overperform'] = df['home_goalsFor_avg'].fillna(1.2) - df['home_xg_avg'].fillna(1.2)
    df['away_xg_overperform'] = df['away_goalsFor_avg'].fillna(1.0) - df['away_xg_avg'].fillna(1.0)
    
    # ==========================================
    # 3. ë“ì‹¤ ê´€ë ¨ íŒŒìƒ í”¼ì²˜
    # ==========================================
    df['goals_diff'] = df['home_goalsFor_avg'].fillna(1.2) - df['away_goalsFor_avg'].fillna(1.0)
    df['goals_against_diff'] = df['home_goalsAgainst_avg'].fillna(1.3) - df['away_goalsAgainst_avg'].fillna(1.5)
    
    # í™ˆ/ì›ì • íŠ¹í™” ë“ì‹¤
    df['home_venue_goals_diff'] = df['home_goalsFor_atHome_avg'].fillna(1.4) - df['away_goalsFor_atAway_avg'].fillna(0.9)
    
    # ==========================================
    # 4. í™ˆ/ì›ì • ìŠ¹ë¥  ê´€ë ¨
    # ==========================================
    df['home_away_winrate_diff'] = (
        df['home_wins_atHome_pct'].fillna(45) - df['away_wins_atAway_pct'].fillna(30)
    ) / 100
    
    # ==========================================
    # 5. ìŠˆíŒ… ê´€ë ¨
    # ==========================================
    df['shots_diff'] = df['home_shotsTotal_avg'].fillna(12) - df['away_shotsTotal_avg'].fillna(12)
    df['shots_on_target_diff'] = df['home_shotsOnTarget_avg'].fillna(4) - df['away_shotsOnTarget_avg'].fillna(4)
    
    # ìŠˆíŒ… ì •í™•ë„
    df['home_shot_accuracy'] = df['home_shotsOnTarget_avg'].fillna(4) / (df['home_shotsTotal_avg'].fillna(12) + 0.1)
    df['away_shot_accuracy'] = df['away_shotsOnTarget_avg'].fillna(4) / (df['away_shotsTotal_avg'].fillna(12) + 0.1)
    df['shot_accuracy_diff'] = df['home_shot_accuracy'] - df['away_shot_accuracy']
    
    # ==========================================
    # 6. í”¼ë¡œë„ ê´€ë ¨
    # ==========================================
    df['rest_diff_normalized'] = df['rest_diff'].fillna(0) / 3  # -1 ~ +1 ë²”ìœ„ë¡œ
    df['fatigue_diff'] = (df['away_matches_14d'].fillna(2) - df['home_matches_14d'].fillna(2)) / 3
    
    # ==========================================
    # 7. H2H ê´€ë ¨ (ì›ì‹œ ë°ì´í„° ìœ ì§€, ê°€ì¤‘ì¹˜ëŠ” ëª¨ë¸ì´ í•™ìŠµ)
    # ==========================================
    # H2H ì‹ ë¢°ë„ (ê²½ê¸° ìˆ˜ ê¸°ë°˜)
    df['h2h_reliability'] = np.minimum(df['h2h_total_matches'].fillna(0) / 10, 1.0)
    
    # H2H í™ˆ ìš°ìœ„
    df['h2h_home_advantage'] = (df['h2h_home_win_pct'].fillna(50) - 50) / 100
    
    # ==========================================
    # 8. ì ìœ ìœ¨/íŒ¨ìŠ¤ ê´€ë ¨
    # ==========================================
    df['possession_diff'] = (
        df['home_possessionPct_avg'].fillna(50) - df['away_possessionPct_avg'].fillna(50)
    ) / 100
    df['pass_accuracy_diff'] = (
        df['home_passAccuracyPct_avg'].fillna(80) - df['away_passAccuracyPct_avg'].fillna(80)
    ) / 100
    
    print(f"âœ… í”¼ì²˜ ê°€ê³µ ì™„ë£Œ")
    
    return df


def get_feature_columns():
    """
    í•™ìŠµì— ì‚¬ìš©í•  í”¼ì²˜ ëª©ë¡
    - ì›ì‹œ í”¼ì²˜ + íŒŒìƒ í”¼ì²˜
    - ìˆ˜ë™ ê°€ì¤‘ì¹˜ ì¡°í•© í”¼ì²˜ ì—†ìŒ!
    """
    
    feature_cols = [
        # === ì›ì‹œ í¼ í”¼ì²˜ (4ê°œ) ===
        'home_form_last3',
        'home_form_last5',
        'away_form_last3',
        'away_form_last5',
        
        # === í¼ íŒŒìƒ í”¼ì²˜ (4ê°œ) ===
        'form_diff_last3',
        'form_diff_last5',
        'home_form_trend',
        'away_form_trend',
        
        # === ì›ì‹œ xG í”¼ì²˜ (4ê°œ) ===
        'home_xg_avg',
        'away_xg_avg',
        'home_xg_atHome_avg',
        'away_xg_atAway_avg',
        
        # === xG íŒŒìƒ í”¼ì²˜ (4ê°œ) ===
        'xg_diff',
        'xg_home_diff',
        'home_xg_overperform',
        'away_xg_overperform',
        
        # === ë“ì‹¤ í”¼ì²˜ (6ê°œ) ===
        'home_goalsFor_avg',
        'away_goalsFor_avg',
        'home_goalsAgainst_avg',
        'away_goalsAgainst_avg',
        'goals_diff',
        'goals_against_diff',
        
        # === í™ˆ/ì›ì • íŠ¹í™” í”¼ì²˜ (5ê°œ) ===
        'home_goalsFor_atHome_avg',
        'away_goalsFor_atAway_avg',
        'home_wins_atHome_pct',
        'away_wins_atAway_pct',
        'home_away_winrate_diff',
        
        # === ìŠˆíŒ… í”¼ì²˜ (5ê°œ) ===
        'home_shotsTotal_avg',
        'away_shotsTotal_avg',
        'shots_diff',
        'shots_on_target_diff',
        'shot_accuracy_diff',
        
        # === í”¼ë¡œë„ í”¼ì²˜ (5ê°œ) ===
        'home_days_rest',
        'away_days_rest',
        'rest_diff',
        'rest_diff_normalized',
        'fatigue_diff',
        
        # === H2H í”¼ì²˜ (4ê°œ) ===
        'h2h_total_matches',
        'h2h_home_win_pct',
        'h2h_reliability',
        'h2h_home_advantage',
        
        # === ì ìœ ìœ¨/íŒ¨ìŠ¤ í”¼ì²˜ (4ê°œ) ===
        'home_possessionPct_avg',
        'away_possessionPct_avg',
        'possession_diff',
        'pass_accuracy_diff',
        
        # === ë¶€ìƒ í”¼ì²˜ (2ê°œ) ===
        'homeInjuryCount',
        'awayInjuryCount',
    ]
    
    return feature_cols


def create_target(df):
    """ìŠ¹ë¬´íŒ¨ ë¼ë²¨ ìƒì„±"""
    def get_result(row):
        if row['homeGoals'] > row['awayGoals']:
            return 'home_win'
        elif row['homeGoals'] < row['awayGoals']:
            return 'away_win'
        else:
            return 'draw'
    
    df['result'] = df.apply(get_result, axis=1)
    return df


def walk_forward_validation(df, feature_cols):
    """
    Walk-Forward ê²€ì¦
    - 2021-2024 í•™ìŠµ â†’ 2025 í…ŒìŠ¤íŠ¸
    - ì‹¤ì œ ì„œë¹„ìŠ¤ì™€ ë™ì¼í•œ ì¡°ê±´
    """
    print("\n" + "="*60)
    print("ğŸ”¬ Walk-Forward ê²€ì¦")
    print("="*60)
    print("   í•™ìŠµ: 2021-2024ë…„ ë°ì´í„°")
    print("   í…ŒìŠ¤íŠ¸: 2025ë…„ ë°ì´í„°")
    print("="*60)
    
    # ë°ì´í„° ë¶„ë¦¬
    train_df = df[df['year'] <= 2024].copy()
    test_df = df[df['year'] >= 2025].copy()
    
    print(f"\n   í•™ìŠµ ë°ì´í„°: {len(train_df)} ê²½ê¸° (2021-2024)")
    print(f"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)} ê²½ê¸° (2025)")
    
    if len(test_df) < 50:
        print("   âš ï¸ 2025ë…„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. 80:20 ë¶„í• ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        split_idx = int(len(df) * 0.8)
        train_df = df[:split_idx].copy()
        test_df = df[split_idx:].copy()
        print(f"   í•™ìŠµ ë°ì´í„°: {len(train_df)} ê²½ê¸°")
        print(f"   í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)} ê²½ê¸°")
    
    # í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
    X_train = train_df[feature_cols].fillna(0)
    X_test = test_df[feature_cols].fillna(0)
    
    le = LabelEncoder()
    y_train = le.fit_transform(train_df['result'])
    y_test = le.transform(test_df['result'])
    
    print(f"\n   í´ë˜ìŠ¤: {list(le.classes_)}")
    print(f"   í”¼ì²˜ ìˆ˜: {len(feature_cols)}")
    
    return X_train, X_test, y_train, y_test, le, test_df


def train_model(X_train, X_test, y_train, y_test, feature_cols):
    """XGBoost ëª¨ë¸ í•™ìŠµ - ê°€ì¤‘ì¹˜ëŠ” ëª¨ë¸ì´ ìë™ìœ¼ë¡œ í•™ìŠµ!"""
    print("\nğŸš€ XGBoost ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    print("   â†’ í”¼ì²˜ ê°„ ìµœì  ê°€ì¤‘ì¹˜ë¥¼ ëª¨ë¸ì´ ìë™ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤!")
    
    model = xgb.XGBClassifier(
        n_estimators=300,
        max_depth=5,
        learning_rate=0.03,
        subsample=0.8,
        colsample_bytree=0.8,
        min_child_weight=3,
        gamma=0.1,
        reg_alpha=0.1,
        reg_lambda=1.0,
        random_state=42,
        eval_metric='mlogloss',
        early_stopping_rounds=30,
    )
    
    model.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        verbose=False
    )
    
    # í‰ê°€
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥:")
    print(f"   ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.1f}%)")
    
    return model, accuracy


def analyze_feature_importance(model, feature_cols, le):
    """
    í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ - XGBoostê°€ í•™ìŠµí•œ ê°€ì¤‘ì¹˜ í™•ì¸!
    """
    print("\n" + "="*60)
    print("ğŸ“Š XGBoostê°€ í•™ìŠµí•œ í”¼ì²˜ ì¤‘ìš”ë„ (ìë™ ê°€ì¤‘ì¹˜)")
    print("="*60)
    
    importance = dict(zip(feature_cols, model.feature_importances_))
    sorted_imp = sorted(importance.items(), key=lambda x: x[1], reverse=True)
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì§‘ê³„
    categories = {
        'í¼': ['form_last3', 'form_last5', 'form_diff', 'form_trend'],
        'xG': ['xg_avg', 'xg_diff', 'xg_overperform', 'xg_atHome', 'xg_atAway'],
        'ë“ì‹¤': ['goalsFor', 'goalsAgainst', 'goals_diff'],
        'í™ˆì›ì •': ['wins_atHome', 'wins_atAway', 'winrate_diff', 'venue'],
        'ìŠˆíŒ…': ['shots', 'shot_accuracy'],
        'H2H': ['h2h'],
        'í”¼ë¡œë„': ['rest', 'fatigue', 'matches_14d'],
        'ì ìœ ìœ¨': ['possession', 'pass'],
        'ë¶€ìƒ': ['Injury'],
    }
    
    category_importance = {cat: 0 for cat in categories}
    
    for feat, imp in sorted_imp:
        for cat, keywords in categories.items():
            if any(kw.lower() in feat.lower() for kw in keywords):
                category_importance[cat] += imp
                break
    
    print("\n[ì¹´í…Œê³ ë¦¬ë³„ ì¤‘ìš”ë„ - ëª¨ë¸ì´ í•™ìŠµí•œ ê²°ê³¼!]")
    sorted_cats = sorted(category_importance.items(), key=lambda x: x[1], reverse=True)
    for cat, imp in sorted_cats:
        bar = "â–ˆ" * int(imp * 50)
        print(f"   {cat:8} {imp*100:5.1f}% {bar}")
    
    print("\n[ê°œë³„ í”¼ì²˜ TOP 15]")
    for i, (feat, imp) in enumerate(sorted_imp[:15], 1):
        bar = "â–ˆ" * int(imp * 100)
        print(f"   {i:2}. {feat:30} {imp*100:5.2f}% {bar}")
    
    print("\n[ê°œë³„ í”¼ì²˜ BOTTOM 5]")
    for feat, imp in sorted_imp[-5:]:
        print(f"       {feat:30} {imp*100:5.2f}%")
    
    return sorted_imp, category_importance


def analyze_predictions(model, X_test, y_test, le, test_df):
    """ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„ - ë°°ë‹¹ê³¼ ë¹„êµ ê°€ëŠ¥í•œ í˜•íƒœë¡œ"""
    print("\n" + "="*60)
    print("ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„")
    print("="*60)
    
    # í™•ë¥  ì˜ˆì¸¡
    probs = model.predict_proba(X_test)
    
    class_order = list(le.classes_)
    home_idx = class_order.index('home_win')
    draw_idx = class_order.index('draw')
    away_idx = class_order.index('away_win')
    
    test_df = test_df.copy()
    test_df['ml_home'] = probs[:, home_idx] * 100
    test_df['ml_draw'] = probs[:, draw_idx] * 100
    test_df['ml_away'] = probs[:, away_idx] * 100
    test_df['ml_pred'] = le.inverse_transform(model.predict(X_test))
    test_df['actual'] = le.inverse_transform(y_test)
    test_df['correct'] = test_df['ml_pred'] == test_df['actual']
    
    # í™•ë¥  ë¶„í¬
    print("\n[ML í™ˆ ìŠ¹ í™•ë¥  ë¶„í¬]")
    bins = [(70, 100), (60, 70), (50, 60), (40, 50), (0, 40)]
    for low, high in bins:
        mask = (test_df['ml_home'] >= low) & (test_df['ml_home'] < high)
        count = mask.sum()
        if count > 0:
            acc = test_df[mask]['correct'].mean() * 100
            print(f"   {low:2}-{high:3}%: {count:3}ê²½ê¸°, ì ì¤‘ë¥  {acc:.1f}%")
    
    print("\n[ML ë¬´ìŠ¹ë¶€ í™•ë¥  ë¶„í¬]")
    bins = [(35, 100), (30, 35), (25, 30), (20, 25), (0, 20)]
    for low, high in bins:
        mask = (test_df['ml_draw'] >= low) & (test_df['ml_draw'] < high)
        count = mask.sum()
        if count > 0:
            acc = test_df[mask & (test_df['actual'] == 'draw')].shape[0] / count * 100 if count > 0 else 0
            print(f"   {low:2}-{high:3}%: {count:3}ê²½ê¸°, ë¬´ìŠ¹ë¶€ ì ì¤‘ë¥  {acc:.1f}%")
    
    # ìƒ˜í”Œ ì˜ˆì¸¡
    print("\n[ì˜ˆì¸¡ ìƒ˜í”Œ 10ê²½ê¸°]")
    sample = test_df.sample(min(10, len(test_df)), random_state=42)
    for _, row in sample.iterrows():
        pred_icon = "âœ…" if row['correct'] else "âŒ"
        print(f"   {pred_icon} ML: í™ˆ{row['ml_home']:.0f}%/ë¬´{row['ml_draw']:.0f}%/ì›{row['ml_away']:.0f}% â†’ {row['ml_pred']} (ì‹¤ì œ: {row['actual']})")
    
    return test_df


def save_model(model, le, feature_cols, accuracy, importance, category_importance):
    """ëª¨ë¸ ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    model_dir = os.path.join(os.path.dirname(__file__), '..', 'models')
    os.makedirs(model_dir, exist_ok=True)
    
    # ëª¨ë¸ ì €ì¥
    model_filename = f"xgboost_v8_{timestamp}.json"
    model_path = os.path.join(model_dir, model_filename)
    model.save_model(model_path)
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    meta = {
        "version": "V8",
        "created_at": timestamp,
        "accuracy": float(accuracy),
        "classes": list(le.classes_),
        "feature_columns": feature_cols,
        "model_file": model_filename,
        "description": "V8 - XGBoost ìë™ ê°€ì¤‘ì¹˜ í•™ìŠµ, Walk-Forward ê²€ì¦",
        "design_principles": [
            "ìˆ˜ë™ ê°€ì¤‘ì¹˜ ì—†ìŒ - ëª¨ë¸ì´ ìë™ í•™ìŠµ",
            "Walk-Forward: 2021-2024 í•™ìŠµ â†’ 2025 í…ŒìŠ¤íŠ¸",
            "í”¼ì²˜ ê°€ê³µì€ í•˜ë˜ ìµœì¢… ê²°í•©ì€ ëª¨ë¸ì—ê²Œ ìœ„ì„",
        ],
        "learned_category_importance": {k: float(v) for k, v in category_importance.items()},
        "feature_importance_top10": [(f, float(i)) for f, i in importance[:10]]
    }
    
    meta_filename = f"xgboost_v8_{timestamp}_meta.json"
    meta_path = os.path.join(model_dir, meta_filename)
    with open(meta_path, 'w', encoding='utf-8') as f:
        json.dump(meta, f, indent=2, ensure_ascii=False)
    
    # latest ì‹¬ë³¼ë¦­ ë§í¬
    import shutil
    latest_model = os.path.join(model_dir, "xgboost_v8_latest.json")
    latest_meta = os.path.join(model_dir, "xgboost_v8_latest_meta.json")
    
    if os.path.exists(latest_model):
        os.remove(latest_model)
    if os.path.exists(latest_meta):
        os.remove(latest_meta)
    
    shutil.copy(model_path, latest_model)
    shutil.copy(meta_path, latest_meta)
    
    print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ:")
    print(f"   {model_path}")
    
    return model_path


def main():
    print("="*60)
    print("ğŸ§  Soccer-Brain V8 ëª¨ë¸")
    print("="*60)
    print("í•µì‹¬: XGBoostê°€ í”¼ì²˜ ê°€ì¤‘ì¹˜ë¥¼ ìë™ìœ¼ë¡œ í•™ìŠµ!")
    print("ê²€ì¦: Walk-Forward (2021-2024 í•™ìŠµ â†’ 2025 í…ŒìŠ¤íŠ¸)")
    print("="*60)
    
    # 1. ë°ì´í„° ë¡œë“œ
    df = get_features_from_db()
    
    # 2. í”¼ì²˜ ê°€ê³µ (ê°€ì¤‘ì¹˜ ì¡°í•© ì—†ìŒ!)
    df = create_features(df)
    
    # 3. íƒ€ê²Ÿ ìƒì„±
    df = create_target(df)
    
    # 4. í”¼ì²˜ ëª©ë¡
    feature_cols = get_feature_columns()
    print(f"\nğŸ“‹ í”¼ì²˜ ìˆ˜: {len(feature_cols)}")
    
    # 5. Walk-Forward ë¶„í• 
    X_train, X_test, y_train, y_test, le, test_df = walk_forward_validation(df, feature_cols)
    
    # 6. ëª¨ë¸ í•™ìŠµ (ê°€ì¤‘ì¹˜ ìë™ í•™ìŠµ!)
    model, accuracy = train_model(X_train, X_test, y_train, y_test, feature_cols)
    
    # 7. í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ (ëª¨ë¸ì´ í•™ìŠµí•œ ê°€ì¤‘ì¹˜ í™•ì¸)
    importance, category_importance = analyze_feature_importance(model, feature_cols, le)
    
    # 8. ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„
    analyze_predictions(model, X_test, y_test, le, test_df)
    
    # 9. ëª¨ë¸ ì €ì¥
    save_model(model, le, feature_cols, accuracy, importance, category_importance)
    
    print("\n" + "="*60)
    print("âœ… V8 ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    print("="*60)
    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. ìœ„ 'ì¹´í…Œê³ ë¦¬ë³„ ì¤‘ìš”ë„'ê°€ XGBoostê°€ í•™ìŠµí•œ ê²°ê³¼ì…ë‹ˆë‹¤")
    print("   2. ë°°ë‹¹ê³¼ ML ë¶ˆì¼ì¹˜ ë¶„ì„ì„ ìœ„í•´ predict_serverë¥¼ V8ë¡œ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”")
    print("="*60)


if __name__ == "__main__":
    main()
